{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test data\n",
    "building_metadata = pd.read_csv(\"building_metadata.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\",parse_dates=[\"timestamp\"])\n",
    "weather_test_data = pd.read_csv(\"weather_test_data_processed.csv\",parse_dates=[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under this section we will be building the final data pipeline. We will be **processing data, creating features, scaling data and predicting using the given model.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_sine(x,num_unique):\n",
    "    '''\n",
    "    Function returns sine transformation of a datetime feature\n",
    "    '''\n",
    "    \n",
    "    return np.sin(np.deg2rad((360/num_unique) * x))\n",
    "\n",
    "\n",
    "def datetime_cosine(x,num_unique):\n",
    "    '''\n",
    "    Function returns cosine transformation of a datetime feature\n",
    "    '''\n",
    "    \n",
    "    return np.cos(np.deg2rad((360/num_unique) * x))\n",
    "\n",
    "\n",
    "def weekend_binary(x):\n",
    "    '''\n",
    "    Function returns binary values based on day type\n",
    "    '''\n",
    "    \n",
    "    if x in list(range(5)):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_pipeline(X): \n",
    "    '''\n",
    "    Final data pipeline that processes a single data point, \n",
    "    performs necessary function and returns the predicted\n",
    "    value\n",
    "    \n",
    "    =====================================================\n",
    "    Parameters:\n",
    "    X: single datapoint with raw features\n",
    "    \n",
    "    =====================================================\n",
    "    Returns:\n",
    "    None \n",
    "    \n",
    "    =====================================================\n",
    "    '''\n",
    "    \n",
    "    # staring clock\n",
    "    start = time()\n",
    "    \n",
    "    ## processing and merging data\n",
    "    \n",
    "    # merging with the buidling metadata\n",
    "    X = X.merge(building_metadata,how=\"inner\",on=[\"building_id\"])\n",
    "    \n",
    "    # merging with the weather data\n",
    "    X = X.merge(weather_test_data,how=\"inner\",on=[\"timestamp\",\"site_id\"])\n",
    "    \n",
    "    # getting the meter id\n",
    "    meter_id = X[\"meter\"].values[0]\n",
    "    \n",
    "    # dropping columns not required\n",
    "    X.drop(labels=[\"row_id\",\"year_built\",\"floor_count\",\"index\",\"meter\"],axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    ## engineering date time features\n",
    "    \n",
    "    # sine and cosine based on hour\n",
    "    X[\"hour\"] = X[\"timestamp\"].apply(lambda x: x.hour)\n",
    "    X[\"hour_x\"] = X[\"hour\"].apply(func=datetime_sine,args=(24,))\n",
    "    X[\"hour_y\"] = X[\"hour\"].apply(func=datetime_cosine,args=(24,))\n",
    "    \n",
    "    # sine and cosine based on day\n",
    "    X[\"day\"] = X[\"timestamp\"].apply(lambda x: x.day) - 1\n",
    "    X[\"day_x\"] = X[\"day\"].apply(func=datetime_sine,args=(31,))\n",
    "    X[\"day_y\"] = X[\"day\"].apply(func=datetime_cosine,args=(31,))\n",
    "    \n",
    "    # sine and cosine based on day of week\n",
    "    X[\"dayofweek\"] = X[\"timestamp\"].apply(lambda x: x.dayofweek)\n",
    "    X[\"dayofweek_x\"] = X[\"dayofweek\"].apply(func=datetime_sine,args=(7,))\n",
    "    X[\"dayofweek_y\"] = X[\"dayofweek\"].apply(func=datetime_cosine,args=(7,))\n",
    "    \n",
    "    # sine and cosine based on month\n",
    "    X[\"month\"] = X[\"timestamp\"].apply(lambda x: x.month) - 1\n",
    "    X[\"month_x\"] = X[\"month\"].apply(func=datetime_sine,args=(12,))\n",
    "    X[\"month_y\"] = X[\"month\"].apply(func=datetime_cosine,args=(12,))\n",
    "    \n",
    "    # binary feature is_weekend\n",
    "    X[\"is_weekend\"] = X[\"dayofweek\"].apply(func=weekend_binary)\n",
    "    \n",
    "    # dropping columns not required further\n",
    "    X.drop(labels=[\"timestamp\",\"hour\",\"day\",\"dayofweek\",\"month\"],axis=1,inplace=True)\n",
    "    \n",
    "    ## encoding categorical features\n",
    "    \n",
    "    # loading the encoder\n",
    "    file = f\"meter_{meter_id}\\encoder.pkl\"\n",
    "    with open(file,\"rb\") as f:\n",
    "        encoder = pickle.load(f)\n",
    "        \n",
    "    # trasnforming the categorical features\n",
    "    X = encoder.transform(X)\n",
    "    \n",
    "    ## scaling numerical features\n",
    "    \n",
    "    # storing dataframe column names\n",
    "    columns = X.columns\n",
    "    \n",
    "    # loading the scaler\n",
    "    file = f\"meter_{meter_id}\\scaler.pkl\"\n",
    "    with open(file,\"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "    \n",
    "    # standardizing \n",
    "    transformed_data = scaler.transform(X)\n",
    "    \n",
    "    # storing as dataframe\n",
    "    X = pd.DataFrame(data=transformed_data,columns=columns)  \n",
    "    \n",
    "    ## predicting using best model (lgbm regressor)\n",
    "    \n",
    "    # loading the model\n",
    "    file = f\"meter_{meter_id}\\lgbm.pkl\"\n",
    "    with open(file,\"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "        \n",
    "    # predicting using loaded model\n",
    "    y = model.predict(X)[0]\n",
    "    \n",
    "    # exp to reverse log transformation\n",
    "    y = np.expm1(y)\n",
    "    \n",
    "    # ending clock\n",
    "    end = time()\n",
    "    \n",
    "    # finding time for function run\n",
    "    time_difference = round((end - start),2)\n",
    "    \n",
    "    # printing results \n",
    "    print(f\"Time to run function: {time_difference}s\")\n",
    "    print(f\"Predicted Energy Consumption: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run function: 0.05s\n",
      "Predicted Energy Consumption: 74.59897364902699\n"
     ]
    }
   ],
   "source": [
    "# sampling point from test data\n",
    "sample = test_data.sample(n=1)\n",
    "\n",
    "# running the pipeline\n",
    "final_pipeline(X=sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
